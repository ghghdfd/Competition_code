{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Ego-vision_resnet50_keras.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOAqba6rihhgmbM6JYYOL+P"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"BptUsfnCqCVp"},"source":["# 데이터 보기\n","import pandas as pd\n","import numpy as np\n","from glob import glob\n","\n","# 이미지데이터 로딩\n","from PIL import Image\n","import cv2\n","from tqdm import tqdm\n","\n","# 파일경로 설정\n","import os\n","import shutil\n","import json\n","\n","# Modeling\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.utils import to_categorical\n","from keras import backend as K \n","from keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\n","from sklearn.model_selection import KFold,StratifiedKFold\n","\n","# Others\n","import os\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","warnings.simplefilter('ignore')\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qpCBvhrnqOjm"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SG6lKaqssOh7"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9fkPbGizsOnJ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ti915y_IsPeD"},"source":["### Data load"]},{"cell_type":"code","metadata":{"id":"L73uEy6-qOmC"},"source":["data_path = '/content/drive/My Drive/hands'\n","\n","train_path = data_path + '/train'\n","test_path = data_path + '/test'\n","\n","hand_gesture = pd.read_csv(data_path + '/hand_gesture_pose.csv')\n","sample_submission = pd.read_csv(data_path + '/sample_submission.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RQjgFULdqOol"},"source":["# Train 데이터에 있는 폴더를 glob로 불러와\n","# sorted method를 통해 숫자 순으로 정렬\n","\n","train_folders = sorted(glob(train_path + '/*'), key = lambda x : int(x.split('/')[-1]))\n","test_folders  = sorted(glob(test_path + '/*'), key = lambda x : int(x.split('/')[-1]))\n","train_folders[:5]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pTgg8aV0qOrP"},"source":["answers = []\n","for train_folder in train_folders :\n","    json_path = glob(train_folder + '/*.json')[0]\n","    js = json.load(open(json_path))\n","    cat = js.get('action')[0]\n","    cat_name = js.get('action')[1]\n","    answers.append([train_folder.replace(data_path,''),cat, cat_name])\n","\n","answers = pd.DataFrame(answers, columns = ['train_path','answer', 'answer_name'])\n","answers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u5JEALNoqamG"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dKDFvAyFqaou"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lySCUjvVsFQG"},"source":["### Preprocessing"]},{"cell_type":"code","metadata":{"id":"NPWTFWeZqOtr","executionInfo":{"status":"ok","timestamp":1634481060124,"user_tz":-540,"elapsed":3,"user":{"displayName":"‍황상호(대학원학생/일반대학원 디지털애널리틱스 융합협동과정)","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"12335864186950017755"}}},"source":["classes = pd.get_dummies(answers[['answer']], columns = ['answer']).to_numpy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nnXow7B4qiUo"},"source":["import concurrent.futures"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YukYrAXQqixv"},"source":["def load(image_path):\n","    img = image.load_img(image_path, target_size=(112,112,3))\n","    img = image.img_to_array(img)\n","    img = img/255\n","    return img\n","\n","def add_ (img):\n","    images.append(img)\n","\n","def start_processing(train_folders):\n","\n","    for idx,train_folder in enumerate(tqdm(train_folders)) : \n","        query_path  = train_folder.replace(data_path,'')\n","        \n","        with concurrent.futures.ProcessPoolExecutor() as executor:\n","            image_paths = sorted(glob(train_folder + '/*.png'), key = lambda x : int(x.split('/')[-1].replace('.png','')))\n","\n","            future_proc = {executor.submit(load, f): f for f in image_paths}\n","            for future in concurrent.futures.as_completed(future_proc):\n","                add_(future.result())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WCpS8edIqi0Y"},"source":["images  = []\n","targets = []\n","start_processing(train_folders[:])\n","\n","for idx,train_folder in enumerate(tqdm(train_folders[:])) : \n","      image_paths = sorted(glob(train_folder + '/*.png'), key = lambda x : int(x.split('/')[-1].replace('.png','')))\n","      target = classes[int(train_folder.split('/')[-1])] \n","      \n","      for image_path in image_paths:\n","          targets.append(target)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4o7RXu2zqi3C"},"source":["X = np.array(images)\n","print('Train X Shape : ', X.shape)\n","\n","y = np.array(targets)\n","print('Train y Shape : ', y.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NLBEMDxQqi5j"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W3TPbvJxsU9Y"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i522l2YEsVAD"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tE20evSbsVZO"},"source":["### Resnet152 Modeling"]},{"cell_type":"code","metadata":{"id":"FoLhLdyOqi8K"},"source":["skf = StratifiedKFold(n_splits = 5, random_state = 2021, shuffle = True)\n","reLR = ReduceLROnPlateau(patience = 4,verbose = 1,factor = 0.5) \n","es =EarlyStopping(monitor='val_loss', patience=6, mode='min')\n","mc = ModelCheckpoint(f'/content/drive/My Drive/hands/model_kf/resnet.h5',save_best_only=True, verbose=0, monitor = 'val_loss', mode = 'min', save_weights_only=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hl5LNQlArOoz"},"source":["def get_model():\n","    baseModel = Resnet152v2(weights='imagenet', include_top=False)\n","    baseModel.trainable = False\n","\n","    model_in = Input(shape = (112,112,3))\n","    base_model = baseModel(model_in)\n","    head_model = GlobalAveragePooling2D()(base_model)\n","    head_model = Dense(256, activation=\"relu\")(head_model)\n","    head_model = Dropout(0.3)(head_model)\n","    model_out = Dense(classes.shape[1], activation=\"softmax\")(head_model)\n","\n","    model = Model(inputs=model_in, outputs=model_out)\n","    model.compile(loss='categorical_crossentropy',optimizer=tf.keras.optimizers.Adam(),metrics=['accuracy'])\n","    \n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_8Zw2bLerOre"},"source":["skf = StratifiedKFold(n_splits = 5, random_state = 2021, shuffle = True)\n","reLR = ReduceLROnPlateau(patience = 4,verbose = 1,factor = 0.5) \n","es =EarlyStopping(monitor='val_loss', patience=6, mode='min')\n","\n","accuracy = []\n","losss=[]\n","models=[]\n","\n","for i, (train, validation) in enumerate(skf.split(X, y.argmax(1))) :\n","    mc = ModelCheckpoint(f'/content/drive/My Drive/hands/model_kf/cv_study{i + 1}.h5',save_best_only=True, verbose=0, monitor = 'val_loss', mode = 'min', save_weights_only=True)\n","    print(\"-\" * 20 +\"Fold_\"+str(i+1)+ \"-\" * 20)\n","    model = get_model()\n","    history = model.fit(X[train], y[train], epochs = 130, validation_data= (X[validation], y[validation]), \n","                        verbose=1,batch_size=64,callbacks=[es,mc,reLR])\n","    model.load_weights(f'/content/drive/My Drive/hands/model_kf/cv_study{i + 1}.h5')\n","    \n","    k_accuracy = '%.4f' % (model.evaluate(X[validation], y[validation])[1])\n","    k_loss = '%.4f' % (model.evaluate(X[validation], y[validation])[0])\n","    \n","    accuracy.append(k_accuracy)\n","    losss.append(k_loss)\n","    models.append(model)\n","\n","print('\\nK-fold cross validation Auc: {}'.format(accuracy))\n","print('\\nK-fold cross validation loss: {}'.format(losss))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XWPuJHkarOt3"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w1pJqw6irOwk"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8JOYU8uasd8P"},"source":["### Test data prediction"]},{"cell_type":"code","metadata":{"id":"ZaDSc3gWrvmZ"},"source":["test_images  = []\n","for test_folder in tqdm(test_folders, total = len(test_folders)) :\n","    image_paths = sorted(glob(test_folder + '/*.png'), key = lambda x : int(x.split('/')[-1].replace('.png','')))\n","    query_path  = test_folder.replace(data_path,'')\n","    test_image = []\n","    for image_path in image_paths:\n","        img = image.load_img(image_path, target_size=(112,112,3))\n","        img = image.img_to_array(img)\n","        img = img/255\n","        test_image.append(img)\n","    test_images.append(test_image)\n","\n","test_images = np.array(test_images)\n","print(test_images.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3T8Ci4Ncrvo9"},"source":["\n","pred=[]\n","for model in models:\n","    predictions = []\n","    for test_image in tqdm(test_images, total = len(test_images)) : \n","        prediction = np.mean(models[0].predict(np.array(test_image)), axis = 0)\n","        predictions.append(prediction)\n","    print(len(predictions))\n","\n","    pred.append(predictions)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F6x1PuTgrvrW"},"source":["sample_submission.iloc[:,1:] = np.mean(pred, axis=0)\n","display(sample_submission.head())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zmLpQ4wDrvuG"},"source":["sample_submission.to_csv('/content/drive/My Drive/hands/resnet152.csv', index=False)"],"execution_count":null,"outputs":[]}]}